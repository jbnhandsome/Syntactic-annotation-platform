{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import os\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conll_8best_Read():\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    #这个函数没测试过 不过多个的没问题，这个应该也没啥问题\n",
    "    def read_single_file(self,file_path,file_name):\n",
    "        #path = E:\\\\baiduyunxiazai\\\\zx\n",
    "        #file_path = \"E:\\\\baiduyunxiazai\\\\zx\\\\top1\\\\notMatch.1\"\n",
    "        paths=['top1','top2','top3','top4','top5','top6','top7','top8']\n",
    "        #file_path = \"E:\\\\baiduyunxiazai\\\\zx\\\\top1\\\\notMatch.1\"\n",
    "        #file_path+paths[j]+notMatch.alldata\n",
    "        file = os.path.join(file_path,paths[0],file_name)\n",
    "        with open(file,'r', encoding='utf-8') as fb:\n",
    "            for line in fb:\n",
    "                line = line.strip('\\n') \n",
    "                if line:\n",
    "                    self.dataset.append(line.split('\\t'))\n",
    "                else:\n",
    "                    self.dataset.append([])\n",
    "        return self.dataset\n",
    "         \n",
    "    def read_mul_file(self,file_path,file_name):\n",
    "        #一共973句话 算上']'\n",
    "        #path = E:\\\\baiduyunxiazai\\\\zx\n",
    "        paths=['top1','top2','top3','top4','top5','top6','top7','top8']\n",
    "        #file_path = \"E:\\\\baiduyunxiazai\\\\zx\\\\top1\\\\notMatch.1\"\n",
    "        for j in range(8):\n",
    "            #file_path+paths[j]+notMatch.alldata\n",
    "            file = os.path.join(file_path,paths[j],file_name)\n",
    "            print(file)\n",
    "            with open(file,'r', encoding='utf-8') as fb:\n",
    "                for line in fb:\n",
    "                    line = line.strip('\\n') \n",
    "                    if line:\n",
    "                        self.dataset.append(line.split('\\t'))\n",
    "                    else:\n",
    "                        self.dataset.append([])\n",
    "        return self.dataset\n",
    "         \n",
    "\n",
    "class Sentence(object):\n",
    "    def __init__(self):\n",
    "        self.sen = \"\" #用来判断句子是否相同\n",
    "        self.idx= [] #存每一个单词的序号\n",
    "        self.word = [] #存每一个单词\n",
    "        self.tag = [] #存储标签\n",
    "        self.dep = [] #存储依赖\n",
    "        self.rel = [] #依赖关系\n",
    "        self.Arc={} #字典\n",
    "        self.special_name=[]\n",
    "        \n",
    "    def equal(self,a,b):\n",
    "        if a == b:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def dep_tree(self):\n",
    "        #这里面把所有的弧都取出来\n",
    "        for i in range(len(self.word)):\n",
    "            if self.dep[i] == '0':\n",
    "                self.Arc[self.special_name[i]] = 'root'\n",
    "            else:\n",
    "                for j in range(len(self.word)):\n",
    "                    if self.idx[j] == self.dep[i]:\n",
    "                        self.Arc[self.special_name[i]] = self.special_name[j]\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_conll(dataset):\n",
    "    Sen = Sentence()\n",
    "    sente = [Sentence() for i in range(1)]\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[i]:\n",
    "            Sen.sen = Sen.sen + dataset[i][1]\n",
    "            Sen.word.append(dataset[i][1])\n",
    "            Sen.idx.append(dataset[i][0])\n",
    "            Sen.tag.append(dataset[i][3])\n",
    "            Sen.dep.append(dataset[i][6])\n",
    "            Sen.rel.append(dataset[i][7])\n",
    "            Sen.special_name.append(str(dataset[i][0])+'|'+str(dataset[i][1]+'|'+str(dataset[i][3])))\n",
    "        else:\n",
    "            Sen.dep_tree()\n",
    "            sente.append(Sen)\n",
    "            Sen = Sentence()\n",
    "    del(sente[0])\n",
    "    print(sente[0].sen)\n",
    "    return sente\n",
    "\n",
    "def find_sent(sen):\n",
    "    se = set() #存储所有已经出现了的句子\n",
    "    dic = {\"\":[]} #为每个句子存储所有它的index\n",
    "    for i in range(len(sen)):\n",
    "        if sen[i].sen not in se:\n",
    "            dic[sen[i].sen]=[i] #为每个句子建立一个空集合\n",
    "        else:\n",
    "            continue #这个句子我们就不统计了 进行一个值的跳过\n",
    "        \n",
    "        for j in range(i+1,len(sen)):\n",
    "            if sen[j].sen not in se and sen[i].sen == sen[j].sen: \n",
    "                dic[sen[i].sen].append(j)\n",
    "        se.add(sen[i].sen)\n",
    "    del(dic[\"\"])\n",
    "    return se,dic\n",
    "\n",
    "#生成graphiz类型的dependency_tree树\n",
    "def generate_DPtree_graphiz(sen,st,dic):\n",
    "    #sen是所有句子的集合，str是\n",
    "    #我们需要为每一个句子生成一棵树，这里的话我们可以选择生成那个句子的树\n",
    "    name = []\n",
    "    for i in dic[st]:\n",
    "        g = Digraph('依存树'+str(i))\n",
    "        g.node(name='root')\n",
    "        #需要让根节点指向0的位置\n",
    "        for j in range(len(sen[i].word)):\n",
    "            #如果需要添加词的属性需要加上下边这一行，否则就不需要\n",
    "            #name.append(str(sen[i].word[j])+'|'+str(sen[i].tag[j]))\n",
    "            g.node(sen[i].special_name[j],fontname=\"Microsoft YaHei\")\n",
    "        for j in range(len(sen[i].word)):\n",
    "            if sen[i].rel[j]=='root':\n",
    "                g.edge('root',sen[i].special_name[j],label=str(sen[i].dep[j]))\n",
    "                \n",
    "            else:\n",
    "                g.edge(sen[i].Arc[sen[i].special_name[j]],sen[i].special_name[j],label=str(sen[i].rel[j]))\n",
    "        g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/baiduyunxiazai/zx/top1\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top2\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top3\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top4\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top5\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top6\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top7\\notMatch.alldata\n",
      "E:/baiduyunxiazai/zx/top8\\notMatch.alldata\n",
      "」\n"
     ]
    }
   ],
   "source": [
    "file_path=\"E:/baiduyunxiazai/zx/\"\n",
    "fila_name=\"notMatch.alldata\"\n",
    "dataset=[]\n",
    "data = Conll_8best_Read(dataset)\n",
    "dataset = data.read_mul_file(file_path,fila_name)\n",
    "sen = load_data_conll(dataset)\n",
    "se,dic = find_sent(sen)\n",
    "generate_DPtree_graphiz(sen,\"只不过，在这之后，张小凡也感觉到，从绑在自己右手臂膀上的那个奇异法宝，却似乎散发着与烧火棍相反的，带着一丝温暖的气息，传进自己的身体。\",dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161, 562, 963, 1364, 1765, 2166, 2567, 2968]\n",
      "只不过，在这之后，张小凡也感觉到，从绑在自己右手臂膀上的那个奇异法宝，却似乎散发着与烧火棍相反的，带着一丝温暖的气息，传进自己的身体。\n"
     ]
    }
   ],
   "source": [
    "print(dic[\"只不过，在这之后，张小凡也感觉到，从绑在自己右手臂膀上的那个奇异法宝，却似乎散发着与烧火棍相反的，带着一丝温暖的气息，传进自己的身体。\"])\n",
    "print(sen[161].sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传进\n",
      "['只', '不过', '，', '在', '这', '之后', '，', '张小凡', '也', '感觉', '到', '，', '从', '绑', '在', '自己', '右', '手', '臂膀', '上', '的', '那', '个', '奇异', '法宝', '，', '却', '似乎', '散发', '着', '与', '烧火棍', '相反', '的', '，', '带', '着', '一', '丝', '温暖', '的', '气息', '，', '传进', '自己', '的', '身体', '。']\n"
     ]
    }
   ],
   "source": [
    "print(sen[161].Arc['，'])\n",
    "print(sen[161].word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "748dbdca4f5d9507dbf5438deb9fb0c5af4d959a1362599ffdf2eaf1f99424f2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
